{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BOTection - Connection State Extraction\n",
    "Created by balahmadi @balahmadi_OX\n",
    "\n",
    "@author: balahmadi - 2020\n",
    "\"\"\"\n",
    "\n",
    "#2. Connection State Extraction: Extract the features (e.g. conn_state}), \n",
    "# producing a key-value store of state transitions and their frequency.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "from collections import defaultdict\n",
    "import csv  # imports the csv module\n",
    "import sys  # imports the sys module\n",
    "import os\n",
    "import timeit\n",
    "import random\n",
    "import copy\n",
    "DATAPATH_Mal = './Data/Processed/Malicious/'\n",
    "DATAPATH_Benign = './Data/Processed/Benign/'\n",
    "DATAPATH_Mixed = './Data/Processed/Mixed/'\n",
    "DATAPATH_Injected = './Data/Processed/Malicious_to_inject/'\n",
    "OUTPATH = '/Data/Features/'\n",
    "DATAPATH = './Data/Processed/'\n",
    "\n",
    "Directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validIP(address):  # Check if value is an ip address\n",
    "    parts = address.split(\".\")\n",
    "    if len(parts) != 4:\n",
    "        return False\n",
    "    for item in parts:\n",
    "        if not 0 <= int(item) <= 255:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLogs_Mixed(fil,f_type ):\n",
    "    \n",
    "    n_flows = [10,15,20,25,30,35]\n",
    "    cols = ['ts','uid','orig_h','id.orig_p','resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','local_resp','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents']\n",
    "    data = pd.read_csv(DATAPATH_Mixed + fil + '/conn.log' , sep = '\\t', skiprows=8, names = cols)\n",
    "    data.drop(data.tail(1).index,inplace=True) \n",
    "    newCol = data[['proto','service','conn_state']].apply(\n",
    "             lambda x: '|'.join(map(str, x)), axis=1)\n",
    "    data['state_proto_service'] = newCol\n",
    "    \n",
    "    unique_IPs = list(set(data['orig_h']))\n",
    "    cleaned_unique_IPs = []\n",
    "    for address in unique_IPs:\n",
    "        if validIP(address):\n",
    "            cleaned_unique_IPs.append(address)\n",
    "    \n",
    "    for ip in cleaned_unique_IPs:\n",
    "        if ip in MalIP:\n",
    "            result = data[(data.resp_h ==ip) | (data.orig_h ==ip)]\n",
    "            for n in n_flows:\n",
    "                dictmatrix_conn = defaultdict(lambda: defaultdict(float))\n",
    "                dictmatrix_sig = defaultdict(lambda: defaultdict(float))\n",
    "                \n",
    "                list_df = [result[i:i+n] for i in range(0,result.shape[0],1)]\n",
    "               \n",
    "                count = 1\n",
    "                for item in list_df:\n",
    "                    conn = list(item['conn_state'])\n",
    "                    sig = list(item['state_proto_service'])\n",
    "                    if len(conn) ==n:\n",
    "                        for ind1 in range(0,len(sig)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_sig.keys() and (sig[ind1],sig[ind2]) in dictmatrix_sig[count].keys():\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])]=dictmatrix_sig[count][(sig[ind1],sig[ind2])] + 1\n",
    "                            else:\n",
    "\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])] = 1\n",
    "\n",
    "                        for ind1 in range(0,len(conn)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_conn.keys() and (conn[ind1],conn[ind2]) in dictmatrix_conn[count].keys():\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])]=dictmatrix_conn[count][(conn[ind1],conn[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])] = 1\n",
    "                    \n",
    "                        count = count + 1\n",
    "                if dictmatrix_conn:\n",
    "                    ensure_dir('./Data/Features/Mixed/Malicious/conn_state/'+ str(n) + '/'  + fil + '/' + ip + '/')\n",
    "                    ensure_dir('./Data/Features/Mixed/Malicious/state_proto_service/' + str(n) + '/' + fil + '/' + ip + '/' )\n",
    "\n",
    "                    with open('./Data/Features/Mixed/Malicious/conn_state/' + str(n) + '/' + fil + '/'+ ip + '/' + ip +'.pickle', 'a') as handle:\n",
    "                         pickle.dump(dictmatrix_conn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    with open('./Data/Features/Mixed/Malicious/state_proto_service/' + str(n) + '/' + fil + '/'  +ip + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                         pickle.dump(dictmatrix_sig, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "        else:\n",
    "            results = data[(data.resp_h ==ip) | (data.orig_h ==ip)]\n",
    "            for n in n_flows:\n",
    "                dictmatrix_conn = defaultdict(lambda: defaultdict(float))\n",
    "                dictmatrix_sig = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "                list_df = [results[i:i+n] for i in range(0,results.shape[0],1)]\n",
    "                count = 1\n",
    "                for item in list_df:\n",
    "                    conn = list(item['conn_state'])\n",
    "                    sig = list(item['state_proto_service'])\n",
    "                    if len(conn) ==n:\n",
    "                        for ind1 in range(0,len(sig)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_sig.keys() and (sig[ind1],sig[ind2]) in dictmatrix_sig[count].keys():\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])]=dictmatrix_sig[count][(sig[ind1],sig[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])] = 1\n",
    "\n",
    "                        for ind1 in range(0,len(conn)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_conn.keys() and (conn[ind1],conn[ind2]) in dictmatrix_conn[count].keys():\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])]=dictmatrix_conn[count][(conn[ind1],conn[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])] = 1\n",
    "                        count = count + 1\n",
    "                \n",
    "                if dictmatrix_conn:\n",
    "                    ensure_dir('./Data/Features/Mixed/Benign/conn_state/'   + str(n) + '/' + fil + '/')\n",
    "                    ensure_dir('./Data/Features/Mixed/Benign/state_proto_service/'   + str(n) + '/' + fil + '/' )    \n",
    "                    with open('./Data/Features/Benign/conn_state/'  + str(n) + '/'+ fil + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                         pickle.dump(dictmatrix_conn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    with open('./Data/Features/Benign/state_proto_service/'  +str(n) + '/'+ fil + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                         pickle.dump(dictmatrix_sig, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLogs(fil,f_type ):\n",
    "    \n",
    "    n_flows = [10,15,20,25,30,35]\n",
    "    \n",
    "    cols = ['ts','uid','orig_h','id.orig_p','resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','local_resp','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents']\n",
    "    data = pd.read_csv(DATAPATH + \"/\" +f_type +\"/\" + fil + '/conn.log' , sep = '\\t', skiprows=8, names = cols)\n",
    "    data.drop(data.tail(1).index,inplace=True) \n",
    "\n",
    "    newCol = data[['proto','service','conn_state']].apply(\n",
    "             lambda x: '|'.join(map(str, x)), axis=1)\n",
    "    data['state_proto_service'] = newCol\n",
    "    \n",
    "    unique_IPs = list(set(data['orig_h']))\n",
    "    cleaned_unique_IPs = []\n",
    "    for address in unique_IPs:\n",
    "        if validIP(address):\n",
    "            cleaned_unique_IPs.append(address)\n",
    "\n",
    "    if f_type == 'Malicious':\n",
    "        for ip in cleaned_unique_IPs:\n",
    "            result = data[(data.resp_h ==ip) | (data.orig_h ==ip)]\n",
    "            for n in n_flows:\n",
    "                dictmatrix_conn = defaultdict(lambda: defaultdict(float))\n",
    "                dictmatrix_sig = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "                \n",
    "                list_df = [result[i:i+n] for i in range(0,result.shape[0],1)]\n",
    "                count = 1\n",
    "                for item in list_df:\n",
    "                    conn = list(item['conn_state'])\n",
    "                    sig = list(item['state_proto_service'])\n",
    "                   \n",
    "                    if len(conn) ==n:\n",
    "                        \n",
    "                        for ind1 in range(0,len(sig)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_sig.keys() and (sig[ind1],sig[ind2]) in dictmatrix_sig[count].keys():\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])]=dictmatrix_sig[count][(sig[ind1],sig[ind2])] + 1\n",
    "                            else:\n",
    "\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])] = 1\n",
    "\n",
    "                        for ind1 in range(0,len(conn)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_conn.keys() and (conn[ind1],conn[ind2]) in dictmatrix_conn[count].keys():\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])]=dictmatrix_conn[count][(conn[ind1],conn[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])] = 1\n",
    "\n",
    "                        count = count + 1\n",
    "                if dictmatrix_conn:\n",
    "                    ensure_dir('./Data/Features/Malicious/conn_state/'   + str(n) + '/' + fil + '/' + ip + '/')\n",
    "                    ensure_dir('./Data/Features/Malicious/state_proto_service/'  + str(n) + '/'  + fil + '/' + ip + '/')\n",
    "                \n",
    "                    with open('./Data/Features/Malicious/conn_state/'  + str(n) + '/' + fil +  '/'+ ip + '/' + ip +'.pickle', 'a') as handle:\n",
    "                        pickle.dump(dictmatrix_conn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    with open('./Data/Features/Malicious/state_proto_service/'  + str(n) + '/' + fil +  '/' +ip + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                        pickle.dump(dictmatrix_sig, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "    else:\n",
    "        print(fil)\n",
    "        print(cleaned_unique_IPs)\n",
    "        for ip in cleaned_unique_IPs:\n",
    "            \n",
    "            result = data[(data.resp_h ==ip) | (data.orig_h ==ip)]\n",
    "     \n",
    "            for n in n_flows:\n",
    "                dictmatrix_conn = defaultdict(lambda: defaultdict(float))\n",
    "                dictmatrix_sig = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "                list_df = [result[i:i+n] for i in range(0,result.shape[0],1)]\n",
    "                count = 1              \n",
    "                for item in list_df:\n",
    "                    conn = list(item['conn_state'])\n",
    "                    sig = list(item['state_proto_service'])\n",
    "                    \n",
    "                    if len(conn) ==n:\n",
    "                        \n",
    "                        for ind1 in range(0,len(sig)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_sig.keys() and (sig[ind1],sig[ind2]) in dictmatrix_sig[count].keys():\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])]=dictmatrix_sig[count][(sig[ind1],sig[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_sig[count][(sig[ind1],sig[ind2])] = 1\n",
    "\n",
    "                        for ind1 in range(0,len(conn)-1):\n",
    "                            ind2 = ind1 + 1\n",
    "                            if count in dictmatrix_conn.keys() and (conn[ind1],conn[ind2]) in dictmatrix_conn[count].keys():\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])]=dictmatrix_conn[count][(conn[ind1],conn[ind2])] + 1\n",
    "                            else:\n",
    "                                dictmatrix_conn[count][(conn[ind1],conn[ind2])] = 1\n",
    "                    \n",
    "                        count = count + 1\n",
    "                         \n",
    "                if dictmatrix_conn: \n",
    "\n",
    "                    ensure_dir('./Data/Features/Benign/conn_state/'  + str(n) + '/' + fil + '/' )\n",
    "                    ensure_dir('./Data/Features/Benign/state_proto_service/' + str(n) + '/'  + fil + '/' )\n",
    "                    with open('./Data/Features/Benign/conn_state/'  + str(n) + '/'+ fil + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                        pickle.dump(dictmatrix_conn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                    with open('./Data/Features/Benign/state_proto_service/'  +str(n) + '/'+ fil + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                        pickle.dump(dictmatrix_sig, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "\n",
    "def ensure_dir(file_dir):\n",
    "    if not os.path.exists(file_dir):\n",
    "        try:\n",
    "            print('Attempting to create directory in the path specified...')\n",
    "            os.makedirs(file_dir)\n",
    "            #print(\"Directory created successfully...\")\n",
    "            return 1\n",
    "        except:\n",
    "            IOError\n",
    "            #print(\"Directory COULD NOT be created in the location specified.\")\n",
    "            sys.exit(0)\n",
    "            return 0\n",
    "   \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLogs_inject(fil):\n",
    "    n= 15\n",
    "    injected_k = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "    cols = ['ts','uid','orig_h','id.orig_p','resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','local_resp','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents']\n",
    "    data = pd.read_csv(DATAPATH_Injected + \"/\" +\"/\" + fil + '/conn.log', sep = '\\t', skiprows=8, names = cols)\n",
    "    data.drop(data.tail(1).index,inplace=True) \n",
    "    newCol = data[['proto','service','conn_state']].apply(\n",
    "             lambda x: '|'.join(map(str, x)), axis=1)\n",
    "    data['signature'] = newCol\n",
    "    \n",
    "    unique_IPs = list(set(data['orig_h']))\n",
    "    cleaned_unique_IPs = []\n",
    "    for address in unique_IPs:\n",
    "        if validIP(address):\n",
    "            cleaned_unique_IPs.append(address)\n",
    "    \n",
    "    for k in injected_k:     \n",
    "        for ip in cleaned_unique_IPs:\n",
    "            states = ['S0','SF','RSTOS0','RSTRH','SH','SHR','OTH']\n",
    "            \n",
    "            result = data[(data.resp_h ==ip) | (data.orig_h ==ip)]\n",
    "\n",
    "            dictmatrix_conn = defaultdict(lambda: defaultdict(float))\n",
    "            dictmatrix_sig = defaultdict(lambda: defaultdict(float))\n",
    "            dictmatrix_history = defaultdict(lambda: defaultdict(float))\n",
    "            \n",
    "            list_df = [result[i:i+n+1] for i in range(0,result.shape[0],1)]\n",
    "            count = 1\n",
    "            for item in list_df:\n",
    "                conn = list(item['conn_state'])\n",
    "                \n",
    "                if len(conn) == n:\n",
    "                   \n",
    "                    visited = []\n",
    "                    indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "                    for i in range(0,k):\n",
    "                        ri = random.choice(indices)\n",
    "                        if ri not in visited:\n",
    "                            visited.append(ri)\n",
    "                            indices.remove(ri)\n",
    "                            temp_states = copy.copy(states)\n",
    "                            s_i = conn[ri]\n",
    "                            if s_i in temp_states:\n",
    "                                temp_states.remove(s_i)\n",
    "                            rs = random.choice(temp_states)\n",
    "                            conn.insert(ri,rs)\n",
    "                    conn = conn[0:n]\n",
    "\n",
    "                for ind1 in range(0,len(conn)-1):\n",
    "                    ind2 = ind1 + 1\n",
    "                    if count in dictmatrix_conn.keys() and (conn[ind1],conn[ind2]) in dictmatrix_conn[count].keys():\n",
    "                        dictmatrix_conn[count][(conn[ind1],conn[ind2])]=dictmatrix_conn[count][(conn[ind1],conn[ind2])] + 1\n",
    "                    else:\n",
    "                        dictmatrix_conn[count][(conn[ind1],conn[ind2])] = 1\n",
    "                count = count + 1\n",
    "            ensure_dir('./Data/Features/Malicious_to_inject/Malicious/conn_state/' + str(k) + '/')\n",
    "            with open('./Data/Features/Malicious_to_inject/Malicious/conn_state/' + str(k) + '/'+ ip +'.pickle', 'a') as handle:\n",
    "                 pickle.dump(dictmatrix_conn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in os.listdir(DATAPATH_Benign):\n",
    "    if not os.path.exists(Directory + OUTPATH + \"/Benign/\" +f) and f.endswith('.pcap'):\n",
    "        if 'conn.log' in os.listdir(DATAPATH + \"/Benign/\" + f ):\n",
    "            readLogs(f, 'Benign')\n",
    "print('Done Encoding Benign files')\n",
    "\n",
    "for f in os.listdir(DATAPATH_Mal):\n",
    "    if not os.path.exists(Directory + OUTPATH + \"/Malicious/\" + f) and f.endswith('.pcap'):\n",
    "        readLogs(f, 'Malicious')\n",
    "print('Done Encoding Malicious files')\n",
    "\n",
    "MalIP = []\n",
    "BenignIPs = []\n",
    "for f in os.listdir(DATAPATH_Mixed):\n",
    "    if not os.path.exists(Directory + OUTPATH + \"/Mixed/\" + f) and f.endswith('.pcap'):\n",
    "        readLogs_Mixed(f, 'Mixed')\n",
    "print('Done Encoding Mixed (malicious, benign) files')\n",
    "\n",
    "for f in os.listdir(DATAPATH_Injected):\n",
    "    if not os.path.exists(Directory + OUTPATH + \"/Malicious_to_inject/\" + f) and f.endswith('.pcap'):\n",
    "        readLogs_inject(f)\n",
    "print('Done Encoding Malicious injected with Benign States')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
